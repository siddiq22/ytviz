{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d50911d",
   "metadata": {},
   "source": [
    "# YouTube's Data Analysts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba69c3",
   "metadata": {},
   "source": [
    "### Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e80c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import googleapiclient.discovery\n",
    "from IPython.display import JSON\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "import imageio\n",
    "import isodate\n",
    "\n",
    "#NLP\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8181bb",
   "metadata": {},
   "source": [
    "### Extracting data from youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f354fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ['AIzaSyBX6d7WD91fwYSO5gtvnxKRmOsuvJHI3vA']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3381dd",
   "metadata": {},
   "source": [
    "#### Some channels which i chose so visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9c69b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/search?part=snippet&q=Alex+The+Analyst&type=channel&maxResults=1&key=AIzaSyBX6d7WD91fwYSO5gtvnxKRmOsuvJHI3vA&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8d30086d6c37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mmaxResults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     )\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'items'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\googleapiclient\\_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\googleapiclient\\http.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/search?part=snippet&q=Alex+The+Analyst&type=channel&maxResults=1&key=AIzaSyBX6d7WD91fwYSO5gtvnxKRmOsuvJHI3vA&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">"
     ]
    }
   ],
   "source": [
    "channel_names = [\n",
    "    \"Alex The Analyst\",\n",
    "    \"Corey Schafer\",\n",
    "    \"Ken Jee\",\n",
    "    \"Mo Chen\",\n",
    "    \"Luke Barousse\",\n",
    "    \"Data Professor\",\n",
    "    \"Tech With Tim\",\n",
    "    \"Data Science Jay\",\n",
    "    \"Nicholas Renotte\",\n",
    "    \"StatQuest with Josh Starmer\"\n",
    "]\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "channel_ids = {}\n",
    "\n",
    "for channel_name in channel_names:\n",
    "    request = youtube.search().list(\n",
    "        part='snippet',\n",
    "        q=channel_name,\n",
    "        type='channel',\n",
    "        maxResults=1\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    if response['items']:\n",
    "        channel_id = response['items'][0]['id']['channelId']\n",
    "        channel_ids[channel_name] = channel_id\n",
    "        print(f\"Channel: {channel_name} | ID: {channel_id}\")\n",
    "    else:\n",
    "        print(f\"Channel: {channel_name} not found.\")\n",
    "\n",
    "print(channel_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_channel_ids = [\n",
    "    \"UC7cs8q-gJRlGwj4A8OmCmXg\",\n",
    "    \"UCCezIgC97PvUuR4_gbFUs5g\",\n",
    "    \"UCiT9RITQ9PW6BhXK0y2jaeg\",\n",
    "    \"UCDybamfye5An6p-j1t2YMsg\",\n",
    "    \"UCLLw7jmFsvfIVaUFsLs8mlQ\",\n",
    "    \"UCV8e2g4IWQqK71bbzGDEI4Q\",\n",
    "    \"UC4JX40jDee_tINbkjycV4Sg\",\n",
    "    \"UCcQx1UnmorvmSEZef4X7-6g\",\n",
    "    \"UCHXa4OpASJEwrHrLeIzw7Yg\",\n",
    "    \"UCtYLUTtgS3k1Fg4y5tAhLbw\"\n",
    "]\n",
    "\n",
    "print(youtube_channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b4338",
   "metadata": {},
   "source": [
    "#### Extract Channel stats from selected channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848992b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \n",
    "    all_data = []\n",
    "\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=','.join(channel_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        data = {'channelName': item['snippet']['title'],\n",
    "                'publishDate': item['snippet']['publishedAt'],\n",
    "                'subscribers': item['statistics']['subscriberCount'],\n",
    "                'views': item['statistics']['viewCount'],\n",
    "                'totalVideos': item['statistics']['videoCount'],\n",
    "                'playlistId': item['contentDetails']['relatedPlaylists']['uploads']\n",
    "        }\n",
    "        all_data.append(data)\n",
    "    all_data = pd.DataFrame(all_data)\n",
    "\n",
    "    return(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db419bed",
   "metadata": {},
   "source": [
    "#### Get video ID's from all the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_ids(youtube, playlist_id):\n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet, contentDetails\",\n",
    "        playlistId= playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        data = {\n",
    "                'videoId': item['contentDetails']['videoId']\n",
    "               }\n",
    "        video_ids.append(data)\n",
    "    \n",
    "    next_page_token = response.get('nextPageToken')  \n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part=\"snippet, contentDetails\",\n",
    "            playlistId= playlist_id,\n",
    "            maxResults = 50,\n",
    "            pageToken = next_page_token\n",
    "            )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            data = {\n",
    "                    'videoId': item['contentDetails']['videoId']\n",
    "               }\n",
    "            video_ids.append(data)\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc542cb0",
   "metadata": {},
   "source": [
    "#### Extract video details like Channeltitle, video title, description etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58976158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(youtube, video_ids):\n",
    "    all_video_info = []\n",
    "    for i in range(0,len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id= ','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for video in response['items']:\n",
    "            # create dictionary of stats I want to keep\n",
    "            stats_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                          'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                          'contentDetails': ['duration', 'definition', 'caption']\n",
    "                        }\n",
    "            \n",
    "            # empty dictionary to keep track of keys and values\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "            \n",
    "            # extract values and append them into empty dictionary\n",
    "            for k in stats_keep.keys():\n",
    "                for v in stats_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "        video_df = pd.DataFrame(all_video_info)\n",
    "    return video_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c418ee44",
   "metadata": {},
   "source": [
    "#### Extract comments from all vidoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51212280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_comments(youtube, video_ids):\n",
    "    all_comments = []\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "            # help https://developers.google.com/youtube/v3/docs/commentThreads?hl=en_US#snippet.topLevelComment\n",
    "            video_comments = [comment['snippet']['topLevelComment']['snippet']['textOriginal'] \n",
    "                              for comment in response['items'][0:10]]\n",
    "            video_comments_info = {'video_id': video_id, 'comments': video_comments}\n",
    "            all_comments.append(video_comments_info)\n",
    "        except:\n",
    "            pass \n",
    "            \n",
    "    all_comments_df = pd.DataFrame(all_comments)\n",
    "    return all_comments_df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d5878",
   "metadata": {},
   "source": [
    "#### Extract Channel Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b98e93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_stats = get_channel_stats(youtube, youtube_channel_ids)\n",
    "channel_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06766a55",
   "metadata": {},
   "source": [
    "#### Extract video stats for all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_ids = list(channel_stats.playlistId.unique())\n",
    "video_ids_list = []\n",
    "\n",
    "for playlist_id in playlist_ids:\n",
    "    video_ids = get_videos_ids(youtube, playlist_id)\n",
    "    video_ids_list.append(video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70e207",
   "metadata": {},
   "source": [
    "#### Group all the lists together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4654a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids_list_clean= list(itertools.chain(*video_ids_list))\n",
    "video_ids_list_clean = [d['videoId'] for d in video_ids_list_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = video_ids_list_clean\n",
    "video_df = get_video_details(youtube, video_ids)\n",
    "video_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36b6a3",
   "metadata": {},
   "source": [
    "#### Extract comments for all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7994495",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_df = get_videos_comments(youtube, video_ids)\n",
    "all_comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ceb30",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5542eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050fa6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d431fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb9d37",
   "metadata": {},
   "source": [
    "#### Converting some columns with numerical values to numeric data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec75dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['viewCount','likeCount','favouriteCount', 'commentCount']\n",
    "video_df[num_cols] = video_df[num_cols].apply(pd.to_numeric, errors = 'coerce', axis =1)\n",
    "\n",
    "#Check\n",
    "video_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a14d22",
   "metadata": {},
   "source": [
    "#### Convert the publishedAt column to a dateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706890d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df['publishedAt'] = pd.to_datetime(video_df['publishedAt'], format=\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "video_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9f62c",
   "metadata": {},
   "source": [
    "#### Create new column from 'publishedAt', which includes the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help: https://stackoverflow.com/questions/29096381/num-day-to-name-day-with-pandas\n",
    "video_df['publishedDayName'] = video_df['publishedAt'].dt.day_name()\n",
    "video_df['publishedMonthName'] = video_df['publishedAt'].dt.month_name()\n",
    "\n",
    "video_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e32ef5",
   "metadata": {},
   "source": [
    "#### convert duration column to seconds with isodate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a23fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help: https://stackoverflow.com/questions/16742381/how-to-convert-youtube-api-duration-to-seconds\n",
    "# time delta help: https://pandas.pydata.org/docs/user_guide/timedeltas.html\n",
    "\n",
    "video_df['durationSec'] = video_df['duration'].apply(lambda x:isodate.parse_duration(x))\n",
    "video_df['durationSec'] = video_df['durationSec'].astype('timedelta64[s]')\n",
    "video_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e88e12",
   "metadata": {},
   "source": [
    "#### Create a column to count tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a26d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df['tagsCount'] = video_df['tags'].apply(lambda x: 0 if x is None else len(x))\n",
    "video_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad769f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_ordered = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "days_ordered_var = pd.api.types.CategoricalDtype(ordered = True, categories = days_ordered)\n",
    "video_df.publishedDayName = video_df.publishedDayName.astype(days_ordered_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "months_ordered = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "          'August', 'September', 'October', 'November', 'December']\n",
    "months_ordered_var = pd.api.types.CategoricalDtype(ordered = True, categories = months_ordered)\n",
    "video_df.publishedMonthName = video_df.publishedMonthName.astype(months_ordered_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.drop(columns = ['favouriteCount'], inplace = True)\n",
    "video_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88852a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df['title_length'] = video_df['title'].apply(lambda x: len(x))\n",
    "video_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e97c9",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dbffe8",
   "metadata": {},
   "source": [
    "### Channel-Level Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb21bd5d",
   "metadata": {},
   "source": [
    "### Total Views Per Channel (Bar Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d90ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def millions(x, pos):\n",
    "    return '%1.1fM' % (x*1e-6)\n",
    "\n",
    "formatter = FuncFormatter(millions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_color = sb.color_palette()[0]\n",
    "plt.figure(figsize = (12, 8))\n",
    "ax = sb.barplot(x = 'channelTitle', y = 'viewCount', \n",
    "                data = video_df.groupby('channelTitle')['viewCount'].sum().sort_values(ascending = False).reset_index(),\n",
    "               color = base_color)\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.title('Total Views per Channel', fontsize = 18)\n",
    "plt.xticks(rotation = 90, fontsize = 12.5)\n",
    "plt.yticks(fontsize = 12.5)\n",
    "plt.xlabel('Channel Title', fontsize = 15)\n",
    "plt.ylabel('Total View Count', fontsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288ad526",
   "metadata": {},
   "source": [
    "#### Amongst all the channels, Tech with tom has the most views with more than 160000k views, significantly greater than the other channels. And with Jay Feng being the channel with the least number of views at 5000k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809747b6",
   "metadata": {},
   "source": [
    "### Videos Published by Day & Month (Histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6811c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize = [12, 8])\n",
    "fig.tight_layout(h_pad=5)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "sb.histplot(data = video_df, x = \"publishedDayName\")\n",
    "plt.title('Videos Published by Day')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sb.histplot(data = video_df, x = \"publishedMonthName\")\n",
    "plt.title('Videos Published by Month');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4bd622",
   "metadata": {},
   "source": [
    "#### An examination of video distribution patterns across days and months revealed interesting trends. The daily analysis showed Tuesday as the peak day for video uploads, though other weekdays maintained comparable levels. Notably, weekend uploads dropped significantly, approximately halving in number. This reduction aligns with the stock market's weekend closure.\n",
    "\n",
    "#### Monthly distribution analysis indicated a generally steady upload rate throughout the year. However, the first and last quarters exhibited a marked increase in activity. During these periods, monthly upload counts consistently exceeded 350 videos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f4c202",
   "metadata": {},
   "source": [
    "### Title Length vs. Views (Scatter Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18594c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = [15, 5])\n",
    "sb.scatterplot(data = video_df, x = 'title_length', y = 'viewCount')\n",
    "ax.yaxis.set_major_formatter(formatter);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646932cb",
   "metadata": {},
   "source": [
    "#### Analysis of the scatterplot reveals no discernible correlation between the length of video titles and their word count. However, an interesting observation emerges: the videos garnering the highest viewership tend to have titles ranging from 20 to 80 characters in length. This suggests that while title length may not directly influence word count, it could potentially impact video popularity within a specific character range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f3b3a",
   "metadata": {},
   "source": [
    "### Video Engagement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc29144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize = [17, 5])\n",
    "\n",
    "sb.scatterplot(data = video_df, x = 'likeCount', y = 'viewCount', ax = ax[0])\n",
    "sb.scatterplot(data = video_df, x = 'tagsCount', y = 'viewCount', ax = ax[1])\n",
    "sb.scatterplot(data = video_df, x = 'commentCount', y = 'viewCount', ax = ax[2])\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].yaxis.set_major_formatter(formatter);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38f169",
   "metadata": {},
   "source": [
    "#### The first scatterplot, comparing likeCount and viewCount, reveals a strong positive correlation. As video views increase, the number of likes tends to rise proportionally. This relationship is intuitive, though it's worth noting that high view counts don't necessarily guarantee positive reception. The absence of dislike data (due to YouTube's removal of this feature) limits our ability to fully assess viewer sentiment.\n",
    "\n",
    "#### The second scatterplot, examining the relationship between viewCount and tagsCount, shows a distinct lack of correlation. The data points form a nearly horizontal line at the bottom of the plot, suggesting that the number of tags has little to no impact on a video's view count. Interestingly, most outliers (videos with exceptionally high view counts) fall within the 10-30 tag range.\n",
    "\n",
    "#### The final scatterplot, comparing viewCount and commentCount, displays a positive relationship, similar to the first plot. However, the correlation appears moderate rather than strong, as the data points are more dispersed. This suggests that while higher view counts generally correspond to more comments, the relationship is less pronounced than that between views and likes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3a9294",
   "metadata": {},
   "source": [
    "### Video Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fcf0ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(video_df[\"durationSec\"], bins=50, edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.title('Distribution of Video Durations Across All Channels', fontsize=18, fontweight='bold', pad=15)\n",
    "plt.xlabel('Duration (Seconds)', fontsize=15, fontweight='bold')\n",
    "plt.ylabel('Video Count', fontsize=15, fontweight='bold')\n",
    "\n",
    "plt.yticks(fontsize=12.5)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b01f34",
   "metadata": {},
   "source": [
    "#### The histogram plot reveals a significant left skew in the distribution of video durations across all channels. The vast majority of videos fall within the range of 0 to 5000 seconds, which translates to 0 to 1 hour, 23 minutes, and 20 seconds. This concentration of shorter videos suggests a preference for more concise content among the channels analyzed.\n",
    "#### The longest video in the dataset has a duration of approximately 8,000 seconds, which is equivalent to 2 hours, 13 minutes, and 20 seconds. This outlier represents a significant departure from the typical video length and could be an exceptional case, such as a long-form interview, an in-depth analysis, or a special event coverage.\n",
    "\n",
    "##### Key observations:\n",
    "\n",
    "##### Typical video length: The majority of videos are relatively short, clustering in the 0-5000 second range.\n",
    "\n",
    "##### Outliers: There are few videos extending beyond the 5000-second mark, with the longest reaching nearly 8000 seconds.\n",
    "\n",
    "##### Content strategy: The prevalence of shorter videos might indicate a strategy to maintain viewer engagement, as briefer content is often more digestible and shareable.\n",
    "\n",
    "#### This distribution pattern suggests that while these channels occasionally produce longer content, their primary focus is on creating videos that can be consumed within approximately 1.5 hours or less, aligning with typical attention spans and viewing habits of online audiences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47be62",
   "metadata": {},
   "source": [
    "### Comments per videos for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_Q3 = (video_df['commentCount'].quantile(0.50))*2\n",
    "\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "ax = sb.violinplot(data = video_df[video_df.commentCount < double_Q3], x = 'channelTitle', y = 'commentCount')\n",
    "plt.xticks(rotation = 90, fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.xlabel(\"Channel Title\", fontsize = 15)\n",
    "plt.ylabel(\"Comment Count\", fontsize = 15)\n",
    "plt.title(\"Violin Distribution Of Comments With Cutoff\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18a145",
   "metadata": {},
   "source": [
    "#### The violin plot reveals the distribution of comment counts for various YouTube channels, with each \"violin\" representing a channel. The width of each violin at any point indicates the frequency of videos receiving that number of comments. \n",
    "\n",
    "#### Key observations include:\n",
    "\n",
    "##### Variance in comment counts: Channels like Statquest with Josh Stammer, Ken Jee and Corey Schafer display thin, elongated violins. This shape suggests a high variance in comment counts, indicating that some videos on these channels receive significantly more comments than others. This could be due to varying content popularity or engagement levels across their videos.\n",
    "\n",
    "##### Consistency in other channels: The wider, more symmetrical violins seen in other channels suggest a more consistent comment pattern. These channels tend to receive a similar number of comments across their videos, indicating a stable audience engagement level.\n",
    "\n",
    "##### Interpretation of violin width: Wider sections of the violin represent a higher concentration of videos with that particular comment count. Therefore, channels with wider violins at certain points have more videos clustering around those comment counts, suggesting more predictable audience interaction.\n",
    "\n",
    "##### Potential factors influencing patterns: It's important to note that these patterns could be influenced by various factors such as channel size, video content, upload frequency, and audience demographics. For instance, channels with narrower violins might produce more diverse content that appeals to different segments of their audience.\n",
    "\n",
    "##### Limitations of the analysis: The cutoff applied to exclude extreme outliers helps in focusing on the typical behavior, but it's worth remembering that these outliers (highly commented videos) exist and could provide valuable insights if analyzed separately.\n",
    "\n",
    "#### This violin plot provides a nuanced view of audience engagement across different channels, highlighting both the typical comment patterns and the variability within each channel's content. It serves as a valuable tool for understanding audience interaction and could inform content strategies for these YouTube creators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab2c1b",
   "metadata": {},
   "source": [
    "### Box plot visualizing Distribution of Views per Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thousands(x, pos):\n",
    "    return '%1.1fK' % (x*1e-3)\n",
    "\n",
    "formatter = FuncFormatter(thousands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 1000000\n",
    "\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "ax = sb.boxplot(data = video_df[video_df.viewCount < cutoff], y = 'channelTitle', x = 'viewCount')\n",
    "ax.xaxis.set_major_formatter(formatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b152bf",
   "metadata": {},
   "source": [
    "#### Top Performers\n",
    "##### Corey Schafer stands out as the channel with the highest median view count, approaching 400,000 views per video. This suggests that Corey Schafer's content consistently attracts a large audience. StatQuest follows as the second-highest performer, indicating strong and steady viewership for their videos as well.\n",
    "\n",
    "#### Mid-Range Performers\n",
    "##### The majority of the other channels display significantly lower interquartile ranges (IQRs) for view counts. This indicates less variability in their typical view counts, with most of their videos receiving fewer than 100,000 views.\n",
    "\n",
    "#### Outliers and Variability\n",
    "##### Many channels, particularly Tech with Tim, exhibit numerous outliers beyond their upper quartiles. This pattern suggests that while these channels generally receive moderate view counts, they occasionally produce videos that significantly outperform their usual metrics. These outliers could represent:\n",
    "\n",
    "##### Viral content that resonated exceptionally well with the audience\n",
    "##### Videos covering trending or highly sought-after topics\n",
    "##### Collaborations or special events that attracted a broader audience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e7b29e",
   "metadata": {},
   "source": [
    "### Average Views Per Upload Day & YouTube Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262bca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "channel_view_means = video_df.groupby(['channelTitle', 'publishedDayName'])['viewCount'].mean().reset_index(name='viewAvg')\n",
    "channel_view_means = channel_view_means.pivot(columns='channelTitle', index='publishedDayName', values='viewAvg')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "cmap = plt.get_cmap(\"Greens\")\n",
    "im = ax.imshow(channel_view_means, cmap=cmap, aspect='auto')\n",
    "\n",
    "cbar = fig.colorbar(im, ax=ax)\n",
    "cbar.set_label('Average View Count', fontsize=14)\n",
    "\n",
    "ax.set_xticks(np.arange(len(channel_view_means.columns)))\n",
    "ax.set_yticks(np.arange(len(channel_view_means.index)))\n",
    "ax.set_xticklabels(channel_view_means.columns, rotation=30, ha='right', fontsize=12)\n",
    "ax.set_yticklabels(channel_view_means.index, fontsize=12)\n",
    "\n",
    "for i in range(len(channel_view_means.index)):\n",
    "    for j in range(len(channel_view_means.columns)):\n",
    "        value = channel_view_means.iloc[i, j]\n",
    "        if not np.isnan(value):  \n",
    "            ax.text(j, i, f'{int(value):,}', ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "plt.title('Average Views Per Upload Day & YouTube Channel', fontsize=18, fontweight='bold', pad=15)\n",
    "plt.xlabel(\"Channel Title\", fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"Uploaded Day Name\", fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0202f5d",
   "metadata": {},
   "source": [
    "### Channel Performance by Upload Day\n",
    "#### Top Performers\n",
    "##### Corey Schafer: Consistently shows the darkest shades of blue across multiple days, indicating high average view counts regardless of the upload day. This suggests a loyal and engaged audience that consistently consumes Schafer's content he demonstrates strong performance with average views never dipping below 80,000 for any upload day. This consistency indicates a stable and dedicated viewer base.\n",
    "##### Alex the Analyst: Achieved the highest single-day average of 660,000 views for videos uploaded on Sundays. This outlier suggests either a particularly successful video or a trend of high-performing Sunday content.\n",
    "\n",
    "#### Strong Contenders\n",
    "##### StatQuest with Josh Stammer: Shows the second darkest shades of blue overall, though not quite matching Corey Schafer's performance. Their peak average of 324,000 views occurs for Monday uploads, indicating a potential sweet spot for their content release.\n",
    "#### Lower Performers\n",
    "##### Jay Feng: Consistently shows the lowest average view counts across all days. Their highest average is only 13,000 views, with most days averaging in the four-digit range. This suggests a smaller, niche audience or potential areas for improvement in content strategy or promotion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f599c2",
   "metadata": {},
   "source": [
    "### Content Strategy Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d190b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_youtube_cloud(data):\n",
    "    image = imageio.imread('cloud.png')\n",
    "    \n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        mask=image,\n",
    "        stopwords=stop_words,\n",
    "        max_words=200,\n",
    "        max_font_size=250,\n",
    "        scale=3,\n",
    "        random_state=1,\n",
    "        color_func=lambda *args, **kwargs: \"blue\",\n",
    "        relative_scaling=0.5\n",
    "    ).generate(str(data))\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,15), dpi=100)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c43c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "video_df['title_no_stopwords'] = video_df['title'].apply(lambda x: [w for w in word_tokenize(x) if w not in stop_words])\n",
    "\n",
    "all_words = list([a for b in video_df['title_no_stopwords'].tolist() for a in b])\n",
    "all_words_str = ' '.join(all_words)\n",
    "plot_youtube_cloud(all_words_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4466cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_comments_df['comments'])):\n",
    "    all_comments_df['comments'][i] = \" \".join(all_comments_df['comments'][i])\n",
    "all_comments_df['comments'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ac12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_df['comments_no_stopwords'] = all_comments_df['comments'].apply(lambda x: [w for w in word_tokenize(x) \n",
    "                                                                                        if w not in stop_words])\n",
    "all_words = list([a for b in all_comments_df['comments_no_stopwords'].tolist() for a in b])\n",
    "all_words_str = ' '.join(all_words)\n",
    "plot_youtube_cloud(all_words_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144e98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
