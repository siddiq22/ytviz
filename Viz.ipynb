{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3016130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import googleapiclient.discovery\n",
    "from IPython.display import JSON\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "import imageio\n",
    "#import isodate\n",
    "\n",
    "#NLP\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12028799",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ['']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197720a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95f8efaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel: Alex The Analyst | ID: UC7cs8q-gJRlGwj4A8OmCmXg\n",
      "Channel: Corey Schafer | ID: UCCezIgC97PvUuR4_gbFUs5g\n",
      "Channel: Ken Jee | ID: UCiT9RITQ9PW6BhXK0y2jaeg\n",
      "Channel: Mo Chen | ID: UCDybamfye5An6p-j1t2YMsg\n",
      "Channel: Luke Barousse | ID: UCLLw7jmFsvfIVaUFsLs8mlQ\n",
      "Channel: Data Professor | ID: UCV8e2g4IWQqK71bbzGDEI4Q\n",
      "Channel: Tech With Tim | ID: UC4JX40jDee_tINbkjycV4Sg\n",
      "Channel: Data Science Jay | ID: UCcQx1UnmorvmSEZef4X7-6g\n",
      "Channel: Nicholas Renotte | ID: UCHXa4OpASJEwrHrLeIzw7Yg\n",
      "Channel: StatQuest with Josh Starmer | ID: UCtYLUTtgS3k1Fg4y5tAhLbw\n",
      "{'Alex The Analyst': 'UC7cs8q-gJRlGwj4A8OmCmXg', 'Corey Schafer': 'UCCezIgC97PvUuR4_gbFUs5g', 'Ken Jee': 'UCiT9RITQ9PW6BhXK0y2jaeg', 'Mo Chen': 'UCDybamfye5An6p-j1t2YMsg', 'Luke Barousse': 'UCLLw7jmFsvfIVaUFsLs8mlQ', 'Data Professor': 'UCV8e2g4IWQqK71bbzGDEI4Q', 'Tech With Tim': 'UC4JX40jDee_tINbkjycV4Sg', 'Data Science Jay': 'UCcQx1UnmorvmSEZef4X7-6g', 'Nicholas Renotte': 'UCHXa4OpASJEwrHrLeIzw7Yg', 'StatQuest with Josh Starmer': 'UCtYLUTtgS3k1Fg4y5tAhLbw'}\n"
     ]
    }
   ],
   "source": [
    "channel_names = [\n",
    "    \"Alex The Analyst\",\n",
    "    \"Corey Schafer\",\n",
    "    \"Ken Jee\",\n",
    "    \"Mo Chen\",\n",
    "    \"Luke Barousse\",\n",
    "    \"Data Professor\",\n",
    "    \"Tech With Tim\",\n",
    "    \"Data Science Jay\",\n",
    "    \"Nicholas Renotte\",\n",
    "    \"StatQuest with Josh Starmer\"\n",
    "]\n",
    "\n",
    "# Build YouTube API service\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Dictionary to store channel names and their IDs\n",
    "channel_ids = {}\n",
    "\n",
    "for channel_name in channel_names:\n",
    "    # Search for the channel\n",
    "    request = youtube.search().list(\n",
    "        part='snippet',\n",
    "        q=channel_name,\n",
    "        type='channel',\n",
    "        maxResults=1\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    # Extract and store the channel ID\n",
    "    if response['items']:\n",
    "        channel_id = response['items'][0]['id']['channelId']\n",
    "        channel_ids[channel_name] = channel_id\n",
    "        print(f\"Channel: {channel_name} | ID: {channel_id}\")\n",
    "    else:\n",
    "        print(f\"Channel: {channel_name} not found.\")\n",
    "\n",
    "# Print all channel IDs\n",
    "print(channel_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b35f3c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UC7cs8q-gJRlGwj4A8OmCmXg', 'UCCezIgC97PvUuR4_gbFUs5g', 'UCiT9RITQ9PW6BhXK0y2jaeg', 'UCDybamfye5An6p-j1t2YMsg', 'UCLLw7jmFsvfIVaUFsLs8mlQ', 'UCV8e2g4IWQqK71bbzGDEI4Q', 'UC4JX40jDee_tINbkjycV4Sg', 'UCcQx1UnmorvmSEZef4X7-6g', 'UCHXa4OpASJEwrHrLeIzw7Yg', 'UCtYLUTtgS3k1Fg4y5tAhLbw']\n"
     ]
    }
   ],
   "source": [
    "youtube_channel_ids = [\n",
    "    \"UC7cs8q-gJRlGwj4A8OmCmXg\",\n",
    "    \"UCCezIgC97PvUuR4_gbFUs5g\",\n",
    "    \"UCiT9RITQ9PW6BhXK0y2jaeg\",\n",
    "    \"UCDybamfye5An6p-j1t2YMsg\",\n",
    "    \"UCLLw7jmFsvfIVaUFsLs8mlQ\",\n",
    "    \"UCV8e2g4IWQqK71bbzGDEI4Q\",\n",
    "    \"UC4JX40jDee_tINbkjycV4Sg\",\n",
    "    \"UCcQx1UnmorvmSEZef4X7-6g\",\n",
    "    \"UCHXa4OpASJEwrHrLeIzw7Yg\",\n",
    "    \"UCtYLUTtgS3k1Fg4y5tAhLbw\"\n",
    "]\n",
    "\n",
    "print(youtube_channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b38d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05aa48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \"\"\"\n",
    "    Function: Gather interested channel stats from youtube creator's channel page\n",
    "    \n",
    "    INPUT:\n",
    "    youtube - build object from googleapiclient.discovery\n",
    "    channel_ids - (list) list of channel ids to be analyzed\n",
    "    \n",
    "    OUTPUT:\n",
    "    all_data - (pandas dataframe) dataframe that consists of the following columns: channelName, publishDate, subscribers, views, totalVideos, playlistId\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=','.join(channel_ids)\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    #loop through items\n",
    "    for item in response['items']:\n",
    "        data = {'channelName': item['snippet']['title'],\n",
    "                'publishDate': item['snippet']['publishedAt'],\n",
    "                'subscribers': item['statistics']['subscriberCount'],\n",
    "                'views': item['statistics']['viewCount'],\n",
    "                'totalVideos': item['statistics']['videoCount'],\n",
    "                'playlistId': item['contentDetails']['relatedPlaylists']['uploads']\n",
    "        }\n",
    "        all_data.append(data)\n",
    "    all_data = pd.DataFrame(all_data)\n",
    "\n",
    "    return(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "683ac6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_ids(youtube, playlist_id):\n",
    "    \"\"\"\n",
    "    Function: Gather videoIds from channel. \n",
    "    \n",
    "    INPUT:\n",
    "    youtube - Get credentials and create an API client/Initialise a Youtube API service object.\n",
    "    playlist_ids - (list) list of playlist ids to be analyzed.\n",
    "    \n",
    "    OUTPUT:\n",
    "    video_ids - (list) list of dictionary that contains all videoId for channel.\n",
    "    \"\"\"\n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet, contentDetails\",\n",
    "        playlistId= playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        data = {\n",
    "                'videoId': item['contentDetails']['videoId']\n",
    "               }\n",
    "        video_ids.append(data)\n",
    "    \n",
    "    next_page_token = response.get('nextPageToken')  \n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part=\"snippet, contentDetails\",\n",
    "            playlistId= playlist_id,\n",
    "            maxResults = 50,\n",
    "            pageToken = next_page_token\n",
    "            )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            data = {\n",
    "                    'videoId': item['contentDetails']['videoId']\n",
    "               }\n",
    "            video_ids.append(data)\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22e5144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Function: Gather interested information from videos and store in dataframe. \n",
    "    \n",
    "    INPUT:\n",
    "    youtube - Get credentials and create an API client/Initialise a Youtube API service object.\n",
    "    video_ids - (list) list of video ids.\n",
    "    \n",
    "    OUTPUT:\n",
    "    video_df - (pandas dataframe) dataframe of video statistics. Includes columns:\n",
    "                 'channelTitle', 'title', 'description', 'tags', 'publishedAt',\n",
    "                 'viewCount', 'likeCount', 'favouriteCount', 'commentCount',\n",
    "                 'duration', 'definition', 'caption'%\n",
    "    \"\"\"\n",
    "    all_video_info = []\n",
    "    for i in range(0,len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id= ','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for video in response['items']:\n",
    "            # create dictionary of stats I want to keep\n",
    "            stats_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                          'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                          'contentDetails': ['duration', 'definition', 'caption']\n",
    "                        }\n",
    "            \n",
    "            # empty dictionary to keep track of keys and values\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "            \n",
    "            # extract values and append them into empty dictionary\n",
    "            for k in stats_keep.keys():\n",
    "                for v in stats_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "        video_df = pd.DataFrame(all_video_info)\n",
    "    return video_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4dc863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_comments(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Function: Gather comments from videos and store in dataframe. \n",
    "    \n",
    "    INPUT:\n",
    "    youtube - Get credentials and create an API client/Initialise a Youtube API service object.\n",
    "    video_ids - (list) list of video ids.\n",
    "    \n",
    "    OUTPUT:\n",
    "    all_comments_df - (pandas dataframe) dataframe of comments. Each video has a max of \n",
    "                        10 comments which are compiled in a list.\n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "            # help https://developers.google.com/youtube/v3/docs/commentThreads?hl=en_US#snippet.topLevelComment\n",
    "            video_comments = [comment['snippet']['topLevelComment']['snippet']['textOriginal'] \n",
    "                              for comment in response['items'][0:10]]\n",
    "            video_comments_info = {'video_id': video_id, 'comments': video_comments}\n",
    "            all_comments.append(video_comments_info)\n",
    "        except:\n",
    "            # dealing with errors\n",
    "            pass \n",
    "            \n",
    "    all_comments_df = pd.DataFrame(all_comments)\n",
    "    return all_comments_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e98a34b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelName</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>views</th>\n",
       "      <th>totalVideos</th>\n",
       "      <th>playlistId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nicholas Renotte</td>\n",
       "      <td>2019-01-26T22:31:46Z</td>\n",
       "      <td>295000</td>\n",
       "      <td>20574899</td>\n",
       "      <td>308</td>\n",
       "      <td>UUHXa4OpASJEwrHrLeIzw7Yg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tech With Tim</td>\n",
       "      <td>2014-04-23T01:57:10Z</td>\n",
       "      <td>1670000</td>\n",
       "      <td>163402027</td>\n",
       "      <td>1312</td>\n",
       "      <td>UU4JX40jDee_tINbkjycV4Sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luke Barousse</td>\n",
       "      <td>2020-08-03T09:02:41.213077Z</td>\n",
       "      <td>498000</td>\n",
       "      <td>24836274</td>\n",
       "      <td>163</td>\n",
       "      <td>UULLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>2006-05-31T22:49:22Z</td>\n",
       "      <td>1400000</td>\n",
       "      <td>100423367</td>\n",
       "      <td>239</td>\n",
       "      <td>UUCezIgC97PvUuR4_gbFUs5g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>2020-01-08T05:04:24.970712Z</td>\n",
       "      <td>972000</td>\n",
       "      <td>45214678</td>\n",
       "      <td>344</td>\n",
       "      <td>UU7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ken Jee</td>\n",
       "      <td>2014-02-28T14:58:24Z</td>\n",
       "      <td>266000</td>\n",
       "      <td>9307997</td>\n",
       "      <td>288</td>\n",
       "      <td>UUiT9RITQ9PW6BhXK0y2jaeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Professor</td>\n",
       "      <td>2019-08-17T15:59:56Z</td>\n",
       "      <td>200000</td>\n",
       "      <td>7156653</td>\n",
       "      <td>353</td>\n",
       "      <td>UUV8e2g4IWQqK71bbzGDEI4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mo Chen</td>\n",
       "      <td>2022-12-25T20:25:38.187653Z</td>\n",
       "      <td>148000</td>\n",
       "      <td>5634083</td>\n",
       "      <td>215</td>\n",
       "      <td>UUDybamfye5An6p-j1t2YMsg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StatQuest with Josh Starmer</td>\n",
       "      <td>2011-05-24T01:52:48Z</td>\n",
       "      <td>1330000</td>\n",
       "      <td>74760977</td>\n",
       "      <td>285</td>\n",
       "      <td>UUtYLUTtgS3k1Fg4y5tAhLbw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jay Feng</td>\n",
       "      <td>2019-11-19T19:16:30.516571Z</td>\n",
       "      <td>52000</td>\n",
       "      <td>3482872</td>\n",
       "      <td>420</td>\n",
       "      <td>UUcQx1UnmorvmSEZef4X7-6g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   channelName                  publishDate subscribers  \\\n",
       "0             Nicholas Renotte         2019-01-26T22:31:46Z      295000   \n",
       "1                Tech With Tim         2014-04-23T01:57:10Z     1670000   \n",
       "2                Luke Barousse  2020-08-03T09:02:41.213077Z      498000   \n",
       "3                Corey Schafer         2006-05-31T22:49:22Z     1400000   \n",
       "4             Alex The Analyst  2020-01-08T05:04:24.970712Z      972000   \n",
       "5                      Ken Jee         2014-02-28T14:58:24Z      266000   \n",
       "6               Data Professor         2019-08-17T15:59:56Z      200000   \n",
       "7                      Mo Chen  2022-12-25T20:25:38.187653Z      148000   \n",
       "8  StatQuest with Josh Starmer         2011-05-24T01:52:48Z     1330000   \n",
       "9                     Jay Feng  2019-11-19T19:16:30.516571Z       52000   \n",
       "\n",
       "       views totalVideos                playlistId  \n",
       "0   20574899         308  UUHXa4OpASJEwrHrLeIzw7Yg  \n",
       "1  163402027        1312  UU4JX40jDee_tINbkjycV4Sg  \n",
       "2   24836274         163  UULLw7jmFsvfIVaUFsLs8mlQ  \n",
       "3  100423367         239  UUCezIgC97PvUuR4_gbFUs5g  \n",
       "4   45214678         344  UU7cs8q-gJRlGwj4A8OmCmXg  \n",
       "5    9307997         288  UUiT9RITQ9PW6BhXK0y2jaeg  \n",
       "6    7156653         353  UUV8e2g4IWQqK71bbzGDEI4Q  \n",
       "7    5634083         215  UUDybamfye5An6p-j1t2YMsg  \n",
       "8   74760977         285  UUtYLUTtgS3k1Fg4y5tAhLbw  \n",
       "9    3482872         420  UUcQx1UnmorvmSEZef4X7-6g  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_stats = get_channel_stats(youtube, youtube_channel_ids)\n",
    "channel_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57256d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
